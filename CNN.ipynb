{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the tensorflow session\n",
      "iteration 0-20: accuracy 0.932\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0a4b409a2a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 train_step.run(feed_dict={x: input_images[n * batch_size:(n + 1) * batch_size],\n\u001b[0;32m--> 114\u001b[0;31m                                           y_: input_labels[n * batch_size:(n + 1) * batch_size], keep_prob: kp})\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# print(\"Running the \" + str(n + 1) + \" batch in \" + str(it + 1) + \" iteration.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1740\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \"\"\"\n\u001b[0;32m-> 1742\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4116\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4118\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "# 用前10000个数据进行10-fold的cross_validation\n",
    "dir = \"/media/gui/LENOVO/学习/AMAZON/train-jpg/\"\n",
    "label_name = \"cloudy\"\n",
    "kp = 0.7 # dropout = 1-kp\n",
    "\n",
    "def read_label(filname,label_name):\n",
    "\n",
    "    with open(\"/media/gui/LENOVO/学习/AMAZON/train_v2.csv/train_v2.csv\") as fl:\n",
    "        raw = fl.readlines()\n",
    "        fl.close()\n",
    "    result = list()\n",
    "    for part in raw:\n",
    "        line = part.strip(\"\\n\").split(\",\")\n",
    "        mutilabels = line[1].strip(\" \")\n",
    "        if label_name in mutilabels:\n",
    "            result.append([1,0])\n",
    "        else:\n",
    "            result.append([0,1])\n",
    "    return result\n",
    "\n",
    "all_input_label = read_label(\"/media/gui/LENOVO/学习/AMAZON/train_v2.csv/train_v2.csv\",label_name)\n",
    "\n",
    "# 定义输入节点，对应于图片像素值矩阵集合和图片标签(即所代表的数字)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 64*64*3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 64, 64, 3])\n",
    "\n",
    "# 定义第一个卷积层的variables和ops\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 3, 16], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[16]))\n",
    "\n",
    "L1_conv = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1_relu = tf.nn.relu(L1_conv + b_conv1)\n",
    "L1_pool = tf.nn.max_pool(L1_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# 定义第二个卷积层的variables和ops\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([3, 3, 16, 32], stddev=0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "L2_conv = tf.nn.conv2d(L1_pool, W_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2_relu = tf.nn.relu(L2_conv + b_conv2)\n",
    "L2_pool = tf.nn.max_pool(L2_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# 全连接层\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([16 * 16 * 32, 256], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[256]))\n",
    "\n",
    "h_pool2_flat = tf.reshape(L2_pool, [-1, 16*16*32])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "# readout层\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([256, 2], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[2]))\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# 定义优化器和训练op\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "# 加入正则化\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS, W_conv1)\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS, W_conv2)\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS, W_fc1)\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS, W_fc2)\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=5.0/50000)\n",
    "reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "cross_entropy = (cross_entropy + reg_term)\n",
    "train_step = tf.train.AdamOptimizer((1e-4)).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "file_prefix = \"/media/gui/LENOVO/学习/AMAZON/project/train-jpg-all-\"\n",
    "data_iteration_num = 3\n",
    "split_count = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Start the tensorflow session\")\n",
    "    '''设置每次训练op的输入个数和迭代次数，这里为了支持任意图片总数，定义了一个余数remainder，\n",
    "    譬如，如果每次训练op的输入个数为60，图片总数为150张，则前面两次各输入60张，最后一次输入30张（余数30）'''\n",
    "    batch_size = 50\n",
    "    iterations = 100\n",
    "\n",
    "    for bi in range(data_iteration_num):\n",
    "        train_data_index = random.randint(0, 8)\n",
    "        input_images = np.loadtxt(file_prefix + str(train_data_index), dtype=\"int\")\n",
    "\n",
    "        # 执行训练迭代\n",
    "        for it in range(iterations):\n",
    "            t_pre = datetime.datetime.now()\n",
    "            # print(\"Start the \"+str(it+1)+\" iteration.\")\n",
    "            # for sp in range(1):\n",
    "            # input_images = np.loadtxt( file_prefix+str(sp),dtype = \"int\")\n",
    "            input_count = len(input_images)\n",
    "            batches_count = int(input_count / batch_size)\n",
    "            remainder = input_count % batch_size\n",
    "            input_labels = all_input_label[(train_data_index*split_count+0):(train_data_index*split_count+input_count)]\n",
    "            for n in range(batches_count):\n",
    "                train_step.run(feed_dict={x: input_images[n * batch_size:(n + 1) * batch_size],\n",
    "                                          y_: input_labels[n * batch_size:(n + 1) * batch_size], keep_prob: kp})\n",
    "                # print(\"Running the \" + str(n + 1) + \" batch in \" + str(it + 1) + \" iteration.\")\n",
    "            if remainder > 0:\n",
    "                start_index = batches_count * batch_size\n",
    "                train_step.run(feed_dict={x: input_images[start_index:input_count - 1],\n",
    "                                          y_: input_labels[start_index:input_count - 1], keep_prob: kp})\n",
    "\n",
    "            iterate_accuracy = 0\n",
    "            if (it + 1) % 20 == 0:\n",
    "                iterate_accuracy = accuracy.eval(feed_dict={x: input_images, y_: input_labels, keep_prob: 1.0})\n",
    "                print('iteration %d-%d: accuracy %s' % (bi,it + 1, iterate_accuracy))\n",
    "                if iterate_accuracy >= 1:\n",
    "                    break\n",
    "\n",
    "        test_images = np.loadtxt(file_prefix + str(9))\n",
    "        test_labels = all_input_label[9000:10000]\n",
    "        print(\"The end of %d out-iteration, The test accuracy is as follows.\" % bi)\n",
    "        print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: test_images, y_: test_labels, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "\n",
    "        # t_after = datetime.datetime.now()\n",
    "        # t = (t_after-t_pre).seconds\n",
    "        # print(\"Have costed \"+str(t)+\" in last iteration.\")\n",
    "\n",
    "    test_images = np.loadtxt(file_prefix + str(9))\n",
    "    test_labels = input_labels = all_input_label[9000:10000]\n",
    "    print(\"Final test accuracy %g\" % accuracy.eval(feed_dict={x: test_images, y_: test_labels, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
