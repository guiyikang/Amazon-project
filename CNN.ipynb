{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the tensorflow session\n",
      "iteration 0-20: accuracy 0.89\n",
      "iteration 0-40: accuracy 0.941\n",
      "iteration 0-60: accuracy 0.94\n",
      "iteration 0-80: accuracy 0.955\n",
      "iteration 0-100: accuracy 0.963\n",
      "The end of 0 out-iteration, The test accuracy is as follows.\n",
      "test accuracy 0.794\n",
      "iteration 1-20: accuracy 0.916\n",
      "iteration 1-40: accuracy 0.941\n",
      "iteration 1-60: accuracy 0.957\n",
      "iteration 1-80: accuracy 0.947\n",
      "iteration 1-100: accuracy 0.958\n",
      "The end of 1 out-iteration, The test accuracy is as follows.\n",
      "test accuracy 0.831\n",
      "iteration 2-20: accuracy 0.951\n",
      "iteration 2-40: accuracy 0.947\n",
      "iteration 2-60: accuracy 0.973\n",
      "iteration 2-80: accuracy 0.975\n",
      "iteration 2-100: accuracy 0.979\n",
      "The end of 2 out-iteration, The test accuracy is as follows.\n",
      "test accuracy 0.828\n",
      "Final test accuracy 0.828\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "# 用前10000个数据进行10-fold的cross_validation\n",
    "dir = \"/media/gui/LENOVO/学习/AMAZON/train-jpg/\"\n",
    "label_name = \"cloudy\"\n",
    "kp = 0.7 # dropout = 1-kp\n",
    "\n",
    "def read_label(filname,label_name):\n",
    "\n",
    "    with open(\"/media/gui/LENOVO/学习/AMAZON/train_v2.csv/train_v2.csv\") as fl:\n",
    "        raw = fl.readlines()\n",
    "        fl.close()\n",
    "    result = list()\n",
    "    for part in raw:\n",
    "        line = part.strip(\"\\n\").split(\",\")\n",
    "        mutilabels = line[1].strip(\" \")\n",
    "        if label_name in mutilabels:\n",
    "            result.append([1,0])\n",
    "        else:\n",
    "            result.append([0,1])\n",
    "    return result\n",
    "\n",
    "all_input_label = read_label(\"/media/gui/LENOVO/学习/AMAZON/train_v2.csv/train_v2.csv\",label_name)\n",
    "\n",
    "# 定义输入节点，对应于图片像素值矩阵集合和图片标签(即所代表的数字)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 64*64*3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 64, 64, 3])\n",
    "\n",
    "# 定义第一个卷积层的variables和ops\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 3, 16], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[16]))\n",
    "\n",
    "L1_conv = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1_relu = tf.nn.relu(L1_conv + b_conv1)\n",
    "L1_pool = tf.nn.max_pool(L1_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# 定义第二个卷积层的variables和ops\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([3, 3, 16, 32], stddev=0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "\n",
    "L2_conv = tf.nn.conv2d(L1_pool, W_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2_relu = tf.nn.relu(L2_conv + b_conv2)\n",
    "L2_pool = tf.nn.max_pool(L2_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# 全连接层\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([16 * 16 * 32, 256], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[256]))\n",
    "\n",
    "h_pool2_flat = tf.reshape(L2_pool, [-1, 16*16*32])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "# readout层\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([256, 2], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[2]))\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# 定义优化器和训练op\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "# 加入正则化\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS, W_conv1)\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS, W_conv2)\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS, W_fc1)\n",
    "tf.add_to_collection(tf.GraphKeys.WEIGHTS, W_fc2)\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=5.0/50000)\n",
    "reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "cross_entropy = (cross_entropy + reg_term)\n",
    "train_step = tf.train.AdamOptimizer((1e-4)).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "file_prefix = \"/media/gui/LENOVO/学习/AMAZON/project/train-jpg-all-\"\n",
    "data_iteration_num = 3\n",
    "split_count = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Start the tensorflow session\")\n",
    "    '''设置每次训练op的输入个数和迭代次数，这里为了支持任意图片总数，定义了一个余数remainder，\n",
    "    譬如，如果每次训练op的输入个数为60，图片总数为150张，则前面两次各输入60张，最后一次输入30张（余数30）'''\n",
    "    batch_size = 50\n",
    "    iterations = 100\n",
    "\n",
    "    for bi in range(data_iteration_num):\n",
    "        train_data_index = random.randint(0, 8)\n",
    "        input_images = np.loadtxt(file_prefix + str(train_data_index), dtype=\"int\")\n",
    "\n",
    "        # 执行训练迭代\n",
    "        for it in range(iterations):\n",
    "            t_pre = datetime.datetime.now()\n",
    "            # print(\"Start the \"+str(it+1)+\" iteration.\")\n",
    "            # for sp in range(1):\n",
    "            # input_images = np.loadtxt( file_prefix+str(sp),dtype = \"int\")\n",
    "            input_count = len(input_images)\n",
    "            batches_count = int(input_count / batch_size)\n",
    "            remainder = input_count % batch_size\n",
    "            input_labels = all_input_label[(train_data_index*split_count+0):(train_data_index*split_count+input_count)]\n",
    "            for n in range(batches_count):\n",
    "                train_step.run(feed_dict={x: input_images[n * batch_size:(n + 1) * batch_size],\n",
    "                                          y_: input_labels[n * batch_size:(n + 1) * batch_size], keep_prob: kp})\n",
    "                # print(\"Running the \" + str(n + 1) + \" batch in \" + str(it + 1) + \" iteration.\")\n",
    "            if remainder > 0:\n",
    "                start_index = batches_count * batch_size\n",
    "                train_step.run(feed_dict={x: input_images[start_index:input_count - 1],\n",
    "                                          y_: input_labels[start_index:input_count - 1], keep_prob: kp})\n",
    "\n",
    "            iterate_accuracy = 0\n",
    "            if (it + 1) % 20 == 0:\n",
    "                iterate_accuracy = accuracy.eval(feed_dict={x: input_images, y_: input_labels, keep_prob: 1.0})\n",
    "                print('iteration %d-%d: accuracy %s' % (bi,it + 1, iterate_accuracy))\n",
    "                if iterate_accuracy >= 1:\n",
    "                    break\n",
    "\n",
    "        test_images = np.loadtxt(file_prefix + str(9))\n",
    "        test_labels = all_input_label[9000:10000]\n",
    "        print(\"The end of %d out-iteration, The test accuracy is as follows.\" % bi)\n",
    "        print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: test_images, y_: test_labels, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "\n",
    "        # t_after = datetime.datetime.now()\n",
    "        # t = (t_after-t_pre).seconds\n",
    "        # print(\"Have costed \"+str(t)+\" in last iteration.\")\n",
    "\n",
    "    test_images = np.loadtxt(file_prefix + str(9))\n",
    "    test_labels = input_labels = all_input_label[9000:10000]\n",
    "    print(\"Final test accuracy %g\" % accuracy.eval(feed_dict={x: test_images, y_: test_labels, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
